{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Latent Dirichlet Allocation - Variational Inference\n",
    "====\n",
    "\n",
    "Based on the paper \"Latent Dirchlet Allocation\" by David M. Blei, Andrew Y. Ng, Michael I. Jordan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import sqrt,mean,square\n",
    "import numpy.linalg as la\n",
    "from scipy.special import digamma, polygamma\n",
    "import numba\n",
    "from numba import jit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!git config --global user.email \"kevinjliang2011@gmail.com\"\n",
    "!git config --global user.name \"Kevin Liang\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters\n",
    "\n",
    "document:    $m = 1,...,M$\n",
    "\n",
    "topic:       $z = 1,...,k$\n",
    "\n",
    "word:        $w = 1,...,N_m$\n",
    "\n",
    "vocabulary : $v = 1,...,V$\n",
    "\n",
    "$\\alpha: 1 \\times k$ Model parameter - vector of topic distribution probabilities for each document\n",
    "\n",
    "$\\beta: k \\times v$ Model parameter - matrix of word probabilities for each topic\n",
    "\n",
    "$\\phi: M \\times N_m \\times k$ Variational parameter - matrix of topic probabilities for each word in each document\n",
    "\n",
    "$\\gamma: M \\times k$ Variational parameter - matrix of topic probabilities for each document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "M = 300\n",
    "k = 10\n",
    "N = np.random.randint(150,200,size=M)\n",
    "V = 30\n",
    "\n",
    "print('N: {0}'.format(N))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Test data and pre-processing\n",
    "Randomly generate test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Completely random structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Generate completely random \"documents\"\n",
    "w_rand = list();\n",
    "\n",
    "for m in range(M):\n",
    "    doc = np.random.randint(V,size=N[m])\n",
    "    w_rand.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w_rand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add some structure\n",
    "Generate data according to the LDA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Arbitrarily choose topics 2,5,7 (zero-indexed) as the most likely\n",
    "alpha_gen = np.array((1,1,10,1,1,20,1,15,1,1))\n",
    "\n",
    "# Arbitrarily choose each topic to have 3 very common words\n",
    "beta_probs = np.ones((V,k)) + np.array([np.arange(V)%k==i for i in range(k)]).T*19\n",
    "beta_gen = np.array(list(map(lambda x: np.random.dirichlet(x),beta_probs.T))).T\n",
    "\n",
    "w_struct = list();\n",
    "theta = np.empty((M,k))\n",
    "\n",
    "# Generate each document\n",
    "for m in range(M):\n",
    "    # Draw topic distribution for the document\n",
    "    theta[m,:] = np.random.dirichlet(alpha_gen,1)[0]\n",
    "    doc = np.array([])\n",
    "    \n",
    "    for n in range(N[m]):\n",
    "        # Draw topic according to document's topic distribution\n",
    "        z_n = np.random.choice(np.arange(k),p=theta[m,:])\n",
    "        # Draw word according to topic\n",
    "        w_n = np.random.choice(np.arange(V),p=beta_gen[:,z_n])\n",
    "        doc = np.append(doc,w_n)\n",
    "    w_struct.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "w_struct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize parameters $\\alpha, \\beta, \\phi$ and $\\gamma$\n",
    "Randomly Initialize parameters to reasonable values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alpha = 100*np.random.dirichlet(np.ones(k),1)[0]\n",
    "beta = np.random.dirichlet(np.ones(V),k).T\n",
    "\n",
    "phi = np.array([1/k*np.ones([N[m],k]) for m in range(M)])\n",
    "gamma = np.tile(alpha,(M,1)) + np.tile(N/k,(k,1)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "beta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "phi.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gamma.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimize variational parameters $\\phi$ and $\\gamma$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Optimize variational parameter phi\n",
    "def opt_phi(beta,gamma,words,M,N,k):\n",
    "    for m in range(M):\n",
    "        for n in range(N[m]):\n",
    "            for i in range(k):\n",
    "                phi[m][n,i] = beta[words[m][n],i] * np.exp(digamma(gamma[m,i]) - digamma(np.sum(gamma[m,:])))\n",
    "            # Normalize across states so phi represents probability over states for each word\n",
    "            phi[m][n,:] = phi[m][n,:]/sum(phi[m][n,:])\n",
    "    return phi\n",
    "\n",
    "\n",
    "## Optimize variational parameter gamma\n",
    "def opt_gamma(alpha,phi,M):\n",
    "    gamma = np.tile(alpha,(M,1)) + np.array(list(map(lambda x: np.sum(x,axis=0),phi)))\n",
    "    return gamma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimate model parameters $\\alpha$ and $\\beta$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Optimize beta\n",
    "def est_beta(phi,words,k,V):\n",
    "    for j in range (V):\n",
    "        w_dnj = [np.tile((word == j),(k,1)).T for word in words]\n",
    "        beta[j,:] = np.sum(np.array(list(map(lambda x: np.sum(x,axis=0),phi*w_dnj))),axis=0)\n",
    "        \n",
    "    # Normalize across states so beta represents probability of each word given the state\n",
    "    for i in range(k):\n",
    "        beta[:,i] = beta[:,i]/sum(beta[:,i])\n",
    "        \n",
    "    return beta\n",
    "\n",
    "\n",
    "## Optimize alpha\n",
    "#  (Newton-Raphson method, for a Hessian with special structure)\n",
    "def est_alpha(alpha,gamma,M,k,nr_max_iters = 1000,tol = 10**-2.0):\n",
    "    for it in range(nr_max_iters):\n",
    "        alpha_old = alpha\n",
    "        \n",
    "        #  Calculate gradient \n",
    "        g = M*(digamma(np.sum(alpha))-digamma(alpha)) + np.sum(digamma(gamma)-np.tile(digamma(np.sum(gamma,axis=1)),(k,1)).T,axis=0)\n",
    "        #  Calculate Hessian diagonal component\n",
    "        h = -M*polygamma(1,alpha) \n",
    "        #  Calculate Hessian constant component\n",
    "        z = polygamma(1,np.sum(alpha))\n",
    "        #  Calculate constant\n",
    "        c = np.sum(g/h)/(z**(-1.0)+np.sum(h**(-1.0)))\n",
    "\n",
    "        #  Update alpha\n",
    "        alpha = alpha - (g-c)/h\n",
    "        \n",
    "        #  Check convergence\n",
    "        if sqrt(mean(square(alpha-alpha_old)))<tol:\n",
    "            break\n",
    "        \n",
    "    return alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expectation Maximization (EM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convergence Criterion\n",
    "The variational inference parameter $\\gamma$ contains the topic likelihoods of every document and is thus what is of interest here.\n",
    "\n",
    "Calculate root-mean-square of the change in $\\gamma$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def converged(gamma,gamma_old,convergence):\n",
    "    print(sqrt(mean(square(gamma-gamma_old))))\n",
    "    return sqrt(mean(square(gamma-gamma_old))) < convergence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inference by iterative EM\n",
    "Continue until convergence criterion above met"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "convergence = 10**(-2.0)\n",
    "successfully_Converged = False\n",
    "max_iters = 10**3\n",
    "\n",
    "for iters in range(max_iters):\n",
    "    print(iters)\n",
    "    gamma_old = gamma\n",
    "    \n",
    "    ## Expectation step: Update variational parameters\n",
    "    phi   = opt_phi(beta,gamma,w_struct,M,N,k)\n",
    "    gamma = opt_gamma(alpha,phi,M)\n",
    "    \n",
    "    ## Maximization step: Update model parameters\n",
    "    beta  = est_beta(phi,w_struct,k,V)\n",
    "    alpha = est_alpha(alpha,gamma,M,k)\n",
    "    \n",
    "    if converged(gamma,gamma_old,convergence):\n",
    "        successfully_Converged = True\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alpha_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "beta_gen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tests \n",
    "Testing out syntax and array dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gamma/np.sum(gamma,axis=1)[:,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Word #11 in document 2 (w_dn)\n",
    "w_rand[1][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[doc == 3 for doc in w_rand]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[doc == 3 for doc in w_rand]*w_rand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.sum(np.array(list(map(lambda x: np.sum(x,axis=0),phi))),axis=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
