<html><head><meta content="text/html; charset=UTF-8" http-equiv="content-type"><style type="text/css">ol.lst-kix_nm8194jyunrd-4.start{counter-reset:lst-ctn-kix_nm8194jyunrd-4 0}.lst-kix_nm8194jyunrd-8>li{counter-increment:lst-ctn-kix_nm8194jyunrd-8}.lst-kix_nm8194jyunrd-2>li{counter-increment:lst-ctn-kix_nm8194jyunrd-2}ol.lst-kix_nm8194jyunrd-8.start{counter-reset:lst-ctn-kix_nm8194jyunrd-8 0}ol.lst-kix_nm8194jyunrd-1{list-style-type:none}ol.lst-kix_nm8194jyunrd-0{list-style-type:none}ol.lst-kix_nm8194jyunrd-3{list-style-type:none}ol.lst-kix_nm8194jyunrd-2{list-style-type:none}.lst-kix_nm8194jyunrd-1>li{counter-increment:lst-ctn-kix_nm8194jyunrd-1}ol.lst-kix_nm8194jyunrd-5{list-style-type:none}ol.lst-kix_nm8194jyunrd-4{list-style-type:none}.lst-kix_nm8194jyunrd-2>li:before{content:"" counter(lst-ctn-kix_nm8194jyunrd-2,lower-roman) ". "}ol.lst-kix_nm8194jyunrd-7{list-style-type:none}ol.lst-kix_nm8194jyunrd-6{list-style-type:none}.lst-kix_nm8194jyunrd-1>li:before{content:"" counter(lst-ctn-kix_nm8194jyunrd-1,lower-latin) ". "}ol.lst-kix_nm8194jyunrd-0.start{counter-reset:lst-ctn-kix_nm8194jyunrd-0 0}ol.lst-kix_nm8194jyunrd-8{list-style-type:none}ol.lst-kix_nm8194jyunrd-3.start{counter-reset:lst-ctn-kix_nm8194jyunrd-3 0}.lst-kix_nm8194jyunrd-3>li:before{content:"" counter(lst-ctn-kix_nm8194jyunrd-3,decimal) ". "}.lst-kix_nm8194jyunrd-4>li:before{content:"" counter(lst-ctn-kix_nm8194jyunrd-4,lower-latin) ". "}.lst-kix_nm8194jyunrd-7>li{counter-increment:lst-ctn-kix_nm8194jyunrd-7}.lst-kix_nm8194jyunrd-6>li:before{content:"" counter(lst-ctn-kix_nm8194jyunrd-6,decimal) ". "}.lst-kix_nm8194jyunrd-5>li:before{content:"" counter(lst-ctn-kix_nm8194jyunrd-5,lower-roman) ". "}.lst-kix_nm8194jyunrd-8>li:before{content:"" counter(lst-ctn-kix_nm8194jyunrd-8,lower-roman) ". "}.lst-kix_nm8194jyunrd-7>li:before{content:"" counter(lst-ctn-kix_nm8194jyunrd-7,lower-latin) ". "}.lst-kix_6y1lujbm1qk5-8>li:before{content:"\0025a0  "}.lst-kix_nm8194jyunrd-5>li{counter-increment:lst-ctn-kix_nm8194jyunrd-5}.lst-kix_6y1lujbm1qk5-7>li:before{content:"\0025cb  "}.lst-kix_6y1lujbm1qk5-6>li:before{content:"\0025cf  "}ol.lst-kix_nm8194jyunrd-6.start{counter-reset:lst-ctn-kix_nm8194jyunrd-6 0}.lst-kix_6y1lujbm1qk5-5>li:before{content:"\0025a0  "}ol.lst-kix_nm8194jyunrd-2.start{counter-reset:lst-ctn-kix_nm8194jyunrd-2 0}.lst-kix_6y1lujbm1qk5-3>li:before{content:"\0025cf  "}.lst-kix_6y1lujbm1qk5-2>li:before{content:"\0025a0  "}.lst-kix_6y1lujbm1qk5-4>li:before{content:"\0025cb  "}.lst-kix_nm8194jyunrd-4>li{counter-increment:lst-ctn-kix_nm8194jyunrd-4}.lst-kix_6y1lujbm1qk5-0>li:before{content:"\0025cf  "}ol.lst-kix_nm8194jyunrd-5.start{counter-reset:lst-ctn-kix_nm8194jyunrd-5 0}.lst-kix_6y1lujbm1qk5-1>li:before{content:"\0025cb  "}.lst-kix_nm8194jyunrd-0>li:before{content:"" counter(lst-ctn-kix_nm8194jyunrd-0,decimal) ". "}ul.lst-kix_6y1lujbm1qk5-4{list-style-type:none}.lst-kix_nm8194jyunrd-0>li{counter-increment:lst-ctn-kix_nm8194jyunrd-0}ol.lst-kix_nm8194jyunrd-1.start{counter-reset:lst-ctn-kix_nm8194jyunrd-1 0}ul.lst-kix_6y1lujbm1qk5-3{list-style-type:none}ol.lst-kix_nm8194jyunrd-7.start{counter-reset:lst-ctn-kix_nm8194jyunrd-7 0}ul.lst-kix_6y1lujbm1qk5-2{list-style-type:none}.lst-kix_nm8194jyunrd-3>li{counter-increment:lst-ctn-kix_nm8194jyunrd-3}ul.lst-kix_6y1lujbm1qk5-1{list-style-type:none}ul.lst-kix_6y1lujbm1qk5-8{list-style-type:none}ul.lst-kix_6y1lujbm1qk5-7{list-style-type:none}ul.lst-kix_6y1lujbm1qk5-6{list-style-type:none}ul.lst-kix_6y1lujbm1qk5-5{list-style-type:none}ul.lst-kix_6y1lujbm1qk5-0{list-style-type:none}.lst-kix_nm8194jyunrd-6>li{counter-increment:lst-ctn-kix_nm8194jyunrd-6}ol{margin:0;padding:0}table td,table th{padding:0}.c1{margin-left:36pt;orphans:2;widows:2;padding-left:0pt}.c0{orphans:2;widows:2;height:11pt}.c8{background-color:#ffffff;max-width:451.4pt;padding:72pt 72pt 72pt 72pt}.c4{padding:0;margin:0}.c2{background-color:#ffffff;font-size:14pt}.c7{line-height:1.4285714285714286;margin-right:22pt}.c3{orphans:2;widows:2}.c5{font-size:14pt}.c6{text-align:center}.title{padding-top:0pt;color:#000000;font-size:26pt;padding-bottom:3pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}.subtitle{padding-top:0pt;color:#666666;font-size:15pt;padding-bottom:16pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}li{color:#000000;font-size:11pt;font-family:"Arial"}p{margin:0;color:#000000;font-size:11pt;font-family:"Arial"}h1{padding-top:20pt;color:#000000;font-size:20pt;padding-bottom:6pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h2{padding-top:18pt;color:#000000;font-size:16pt;padding-bottom:6pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h3{padding-top:16pt;color:#434343;font-size:14pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h4{padding-top:14pt;color:#666666;font-size:12pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h5{padding-top:12pt;color:#666666;font-size:11pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h6{padding-top:12pt;color:#666666;font-size:11pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;font-style:italic;orphans:2;widows:2;text-align:left}</style></head><body class="c8"><p class="c3 c6"><span class="c5">Abstract</span></p><p class="c0 c6"><span class="c5"></span></p><p class="c3"><span>Latent Dirichlet Allocation (LDA) is a Bayes statistical model of text corpora proposed in a paper by David Blei, Andrew Ng, and Michael Jordan in 2003. The model is hierarchical in nature, in that each word in a document is generated from a topic, and the mixture of topics for each document is determined by the document&rsquo;s distribution of topics. This distribution of mixtures and the probability of generating a particular word given a topic are parameters that help characterize a corpus. The aim of this project is to implement LDA in Python and perform classification. In particular, to test that the algorithm works, given training documents from 5 separate corpora (Enron emails, NIPS papers, KOS blog entries, NYTimes news articles, and PubMed abstracts), the goal will be to infer the corpora-level parameters of each and then identify the corpora of unknown test documents. This will be done by calculating the marginal probability of generating each test document for each of the inferred corpus parameters. The corpus with the highest probability will then be selected as the source. The accuracy of this test will be compared to other text classification algorithms, such as the simple Latent Semantic Analysis approach done in a previous homework and functions from the gensim package. </span></p><p class="c0"><span class="c5"></span></p><p class="c0"><span class="c5"></span></p><p class="c3 c7"><span class="c2">Preliminary section and subsection headings:</span></p><p class="c0"><span></span></p><ol class="c4 lst-kix_nm8194jyunrd-0 start" start="1"><li class="c1"><span>Background</span></li><li class="c1"><span>Algorithm Description</span></li><li class="c1"><span>Data Set</span></li></ol><p class="c3"><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;https://archive.ics.uci.edu/ml/datasets/Bag+of+Words</span></p><ol class="c4 lst-kix_nm8194jyunrd-0" start="4"><li class="c1"><span>Implementation</span></li><li class="c1"><span>Test</span></li><li class="c1"><span>Application and Comparison</span></li><li class="c1"><span>Conclusion</span></li></ol></body></html>